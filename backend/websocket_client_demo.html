<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QuantAI Restaurant - WebSocket Demo</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .container {
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }
        textarea {
            width: 100%;
            padding: 10px;
            border-radius: 4px;
            border: 1px solid #ddd;
            margin-bottom: 10px;
            resize: vertical;
            min-height: 100px;
        }
        button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 10px 15px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        .response {
            background-color: #f9f9f9;
            border-left: 4px solid #4CAF50;
            padding: 10px;
            margin-top: 20px;
            white-space: pre-wrap;
            min-height: 100px;
        }
        .error {
            color: red;
            font-weight: bold;
        }
        .status {
            color: #666;
            font-style: italic;
            margin-top: 10px;
        }
        .tab-container {
            display: flex;
            margin-bottom: 20px;
        }
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            background-color: #ddd;
            border: none;
            outline: none;
            border-radius: 4px 4px 0 0;
            margin-right: 5px;
        }
        .tab.active {
            background-color: white;
            border-bottom: 2px solid #4CAF50;
        }
        .tab-content {
            display: none;
        }
        .tab-content.active {
            display: block;
        }
        audio {
            width: 100%;
            margin-top: 20px;
        }
        #conversation-output {
            max-height: 300px;
            overflow-y: auto;
            padding: 10px;
            background-color: #f9f9f9;
            border-radius: 4px;
            margin-top: 10px;
        }
        .message {
            margin-bottom: 10px;
            padding: 8px 12px;
            border-radius: 4px;
        }
        .user-message {
            background-color: #e3f2fd;
            text-align: right;
            margin-left: 20%;
        }
        .bot-message {
            background-color: #f1f8e9;
            margin-right: 20%;
        }
    </style>
</head>
<body>
    <h1>QuantAI Restaurant - WebSocket Demo</h1>

    <div class="tab-container">
        <button class="tab active" onclick="openTab(event, 'tts-tab')">TTS Streaming</button>
        <button class="tab" onclick="openTab(event, 'conversation-tab')">Conversation</button>
    </div>

    <div id="tts-tab" class="tab-content active container">
        <h2>Text-to-Speech Streaming</h2>
        <textarea id="tts-text" placeholder="Enter text to convert to speech...">Kia ora, welcome to QuantAI Restaurant in Auckland! How may I assist you today?</textarea>
        <div>
            <label for="language">Language:</label>
            <select id="language">
                <option value="en">English</option>
                <option value="es">Spanish</option>
                <option value="fr">French</option>
                <option value="de">German</option>
                <option value="it">Italian</option>
            </select>
        </div>
        <button id="tts-button" onclick="streamTTS()">Generate Speech</button>
        <div class="status" id="tts-status"></div>
        <audio id="tts-audio" controls></audio>
    </div>

    <div id="conversation-tab" class="tab-content container">
        <h2>Real-time Conversation</h2>
        <textarea id="conversation-text" placeholder="Enter your message...">What's on the menu today?</textarea>
        <div>
            <label for="conv-language">Language:</label>
            <select id="conv-language">
                <option value="en">English</option>
                <option value="es">Spanish</option>
                <option value="fr">French</option>
                <option value="de">German</option>
                <option value="it">Italian</option>
            </select>
        </div>
        <button id="conversation-button" onclick="startConversation()">Send Message</button>
        <div class="status" id="conversation-status"></div>
        <div id="conversation-output"></div>
        <audio id="conversation-audio" controls></audio>
    </div>

    <script>
        // WebSocket connections
        let ttsSocket = null;
        let conversationSocket = null;
        
        // Audio context and processing
        let audioContext = null;
        let audioQueue = [];
        let isPlaying = false;

        // Server URL (change this to match your server)
        const SERVER_URL = 'ws://localhost:8006';
        
        // Initialize audio context on user interaction
        document.addEventListener('click', initAudioContext, { once: true });
        
        function initAudioContext() {
            try {
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContext();
                console.log('AudioContext initialized');
            } catch (e) {
                console.error('Web Audio API not supported:', e);
            }
        }

        // Tab switching functionality
        function openTab(evt, tabName) {
            const tabs = document.getElementsByClassName('tab');
            for (let i = 0; i < tabs.length; i++) {
                tabs[i].className = tabs[i].className.replace(' active', '');
            }
            
            const tabContents = document.getElementsByClassName('tab-content');
            for (let i = 0; i < tabContents.length; i++) {
                tabContents[i].className = tabContents[i].className.replace(' active', '');
            }
            
            document.getElementById(tabName).className += ' active';
            evt.currentTarget.className += ' active';
        }

        // TTS Streaming functionality
        function streamTTS() {
            if (!audioContext) initAudioContext();
            
            const text = document.getElementById('tts-text').value;
            const language = document.getElementById('language').value;
            const statusElement = document.getElementById('tts-status');
            const audioElement = document.getElementById('tts-audio');
            const button = document.getElementById('tts-button');
            
            if (!text) {
                statusElement.textContent = 'Please enter some text.';
                return;
            }
            
            // Clear previous audio
            audioElement.src = '';
            audioQueue = [];
            isPlaying = false;
            
            // Disable button during processing
            button.disabled = true;
            statusElement.textContent = 'Connecting...';
            
            // Close previous connection if exists
            if (ttsSocket && ttsSocket.readyState === WebSocket.OPEN) {
                ttsSocket.close();
            }
            
            // Connect to WebSocket
            ttsSocket = new WebSocket(`${SERVER_URL}/ws/tts`);
            
            // Binary data chunks
            const chunks = [];
            
            ttsSocket.onopen = function() {
                statusElement.textContent = 'Connected. Generating speech...';
                
                // Send the TTS request
                ttsSocket.send(JSON.stringify({
                    text: text,
                    language: language,
                    chunk_size: 1024
                }));
            };
            
            ttsSocket.onmessage = function(event) {
                if (event.data instanceof Blob) {
                    // Audio chunk received
                    chunks.push(event.data);
                    statusElement.textContent = `Receiving audio... (${chunks.length} chunks)`;
                    
                    // Process the audio chunk
                    processAudioChunk(event.data);
                } else {
                    // JSON message received
                    try {
                        const message = JSON.parse(event.data);
                        
                        if (message.status === 'start') {
                            statusElement.textContent = 'Started generating speech...';
                        } else if (message.status === 'end') {
                            statusElement.textContent = `Completed! Received ${message.chunks} audio chunks.`;
                            
                            // Create final audio blob when all chunks are received
                            const audioBlob = new Blob(chunks, { type: 'audio/wav' });
                            const audioUrl = URL.createObjectURL(audioBlob);
                            audioElement.src = audioUrl;
                            
                            // Re-enable button
                            button.disabled = false;
                        } else if (message.error) {
                            statusElement.textContent = `Error: ${message.error}`;
                            button.disabled = false;
                        }
                    } catch (e) {
                        console.error('Error parsing JSON message:', e);
                    }
                }
            };
            
            ttsSocket.onerror = function(error) {
                statusElement.textContent = `WebSocket error: ${error}`;
                button.disabled = false;
            };
            
            ttsSocket.onclose = function() {
                console.log('TTS WebSocket connection closed');
                button.disabled = false;
            };
        }

        // Process audio chunk for real-time playback
        function processAudioChunk(chunk) {
            if (!audioContext) return;
            
            const fileReader = new FileReader();
            fileReader.onload = function() {
                audioContext.decodeAudioData(fileReader.result)
                    .then(buffer => {
                        audioQueue.push(buffer);
                        if (!isPlaying) {
                            playNextInQueue();
                        }
                    })
                    .catch(err => console.error('Error decoding audio data:', err));
            };
            fileReader.readAsArrayBuffer(chunk);
        }

        // Play audio chunks in sequence
        function playNextInQueue() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }
            
            isPlaying = true;
            const buffer = audioQueue.shift();
            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            source.onended = playNextInQueue;
            source.start(0);
        }

        // Conversation functionality
        function startConversation() {
            if (!audioContext) initAudioContext();
            
            const text = document.getElementById('conversation-text').value;
            const language = document.getElementById('conv-language').value;
            const statusElement = document.getElementById('conversation-status');
            const outputElement = document.getElementById('conversation-output');
            const audioElement = document.getElementById('conversation-audio');
            const button = document.getElementById('conversation-button');
            
            if (!text) {
                statusElement.textContent = 'Please enter a message.';
                return;
            }
            
            // Clear previous audio
            audioElement.src = '';
            audioQueue = [];
            isPlaying = false;
            
            // Disable button during processing
            button.disabled = true;
            statusElement.textContent = 'Connecting...';
            
            // Add user message to output
            outputElement.innerHTML += `<div class="message user-message">${text}</div>`;
            outputElement.scrollTop = outputElement.scrollHeight;
            
            // Close previous connection if exists
            if (conversationSocket && conversationSocket.readyState === WebSocket.OPEN) {
                conversationSocket.close();
            }
            
            // Connect to WebSocket
            conversationSocket = new WebSocket(`${SERVER_URL}/ws/conversation`);
            
            // For storing the bot's response
            let botResponse = '';
            
            // For collecting audio chunks
            const audioChunks = [];
            
            conversationSocket.onopen = function() {
                statusElement.textContent = 'Connected. Sending message...';
                
                // Send the message
                conversationSocket.send(JSON.stringify({
                    text: text,
                    language: language
                }));
                
                // Clear the input field
                document.getElementById('conversation-text').value = '';
            };
            
            conversationSocket.onmessage = function(event) {
                if (event.data instanceof Blob) {
                    // Audio chunk received
                    audioChunks.push(event.data);
                    statusElement.textContent = `Receiving audio... (${audioChunks.length} chunks)`;
                    
                    // Process the audio chunk for real-time playback
                    processAudioChunk(event.data);
                } else {
                    // JSON message received
                    try {
                        const message = JSON.parse(event.data);
                        
                        if (message.type === 'text' && message.chunk) {
                            // Text response chunk
                            botResponse += message.chunk;
                            
                            // Update the conversation output
                            const botMessageElement = document.querySelector('#conversation-output .bot-message:last-child');
                            if (botMessageElement) {
                                botMessageElement.textContent = botResponse;
                            } else {
                                outputElement.innerHTML += `<div class="message bot-message">${botResponse}</div>`;
                            }
                            outputElement.scrollTop = outputElement.scrollHeight;
                        } else if (message.status === 'processing') {
                            if (message.type === 'text') {
                                statusElement.textContent = 'Processing your message...';
                                // Create an empty bot message that will be updated
                                outputElement.innerHTML += `<div class="message bot-message"></div>`;
                            } else if (message.type === 'audio') {
                                statusElement.textContent = 'Generating speech...';
                            }
                        } else if (message.status === 'complete') {
                            statusElement.textContent = 'Conversation complete!';
                            
                            // Create final audio blob when all chunks are received
                            if (audioChunks.length > 0) {
                                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                                const audioUrl = URL.createObjectURL(audioBlob);
                                audioElement.src = audioUrl;
                            }
                            
                            // Re-enable button
                            button.disabled = false;
                        } else if (message.error) {
                            statusElement.textContent = `Error: ${message.error}`;
                            outputElement.innerHTML += `<div class="message bot-message error">Error: ${message.error}</div>`;
                            button.disabled = false;
                        }
                    } catch (e) {
                        console.error('Error parsing JSON message:', e);
                    }
                }
            };
            
            conversationSocket.onerror = function(error) {
                statusElement.textContent = `WebSocket error: ${error}`;
                button.disabled = false;
            };
            
            conversationSocket.onclose = function() {
                console.log('Conversation WebSocket connection closed');
                button.disabled = false;
            };
        }
    </script>
</body>
</html> 